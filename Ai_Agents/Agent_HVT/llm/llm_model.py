import os
from dotenv import load_dotenv
from langchain_google_genai.chat_models import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate

load_dotenv()

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

def get_llm():
    return ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",
        temperature=0,
        google_api_key=GOOGLE_API_KEY,
    )

if __name__ == "__main__":
    llm = get_llm()

    # 驻 驻砖 注 砖转  {question}
    simple_template = PromptTemplate.from_template(
        "注 注专转 拽爪专: {question}"
    )
    prompt_text = simple_template.format(question="  GPT?")
    response = llm.invoke(prompt_text)
    print(" 转砖 驻 驻砖:")
    print(response)

    print("\n" + "-"*40 + "\n")

    # 驻 驻专 转专 注 专转 驻专转 砖转 砖转砖
    detailed_template = PromptTemplate.from_template(
        "转 注专 .\n"
        "注 注专转 爪专 专专 住专转.\n"
        "砖: {question}\n"
        " 驻砖专, 住祝 转 拽."
    )
    prompt_text_detailed = detailed_template.format(question=" 注 转 ?")
    response_detailed = llm.invoke(prompt_text_detailed)
    print(" 转砖 驻 驻专:")
    print(response_detailed)
