import os
import zipfile
import pandas as pd
import matplotlib.pyplot as plt
from langchain_core.tools import BaseTool
from typing import ClassVar

# ğŸ—‚ï¸ ××©×ª× ×™× ×’×œ×•×‘×œ×™×™×
GLOBAL_LOADED_DATA = None
GLOBAL_SOURCE_SUMMARY = None

# ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ×œ×’×œ×•×‘×œ×™×
def get_loaded_data():
    return GLOBAL_LOADED_DATA

def get_data_summary():
    return GLOBAL_SOURCE_SUMMARY

# ğŸ”§ ×›×œ×™ 1 â€“ ×˜×¢×™× ×”
class DataLoaderTool(BaseTool):
    name: ClassVar[str] = "data_loader_tool"
    description: ClassVar[str] = "Loads a CSV file or a ZIP file containing CSVs into memory. Supports nested folders inside ZIP."

    def _run(self, file_path: str) -> str:
        global GLOBAL_LOADED_DATA, GLOBAL_SOURCE_SUMMARY
        dfs_loaded = []

        file_path = file_path.strip()

        if not os.path.exists(file_path):
            return f"âŒ ×”× ×ª×™×‘ ×œ× ×§×™×™×: {file_path}"

        if file_path.lower().endswith(".csv"):
            try:
                df = pd.read_csv(file_path)
                GLOBAL_LOADED_DATA = df
                GLOBAL_SOURCE_SUMMARY = [(os.path.basename(file_path), len(df))]
                return f"âœ… {os.path.basename(file_path)} loaded successfully."
            except Exception as e:
                return f"âŒ Failed to load CSV: {str(e)}"

        elif file_path.lower().endswith(".zip"):
            try:
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    csv_files = [f for f in zip_ref.namelist() if f.lower().endswith(".csv")]
                    if not csv_files:
                        return "âš ï¸ ×œ× × ××¦××• ×§×•×‘×¦×™ CSV ×‘×ª×•×š ×§×•×‘×¥ ×”-ZIP."

                    combined_df = pd.DataFrame()
                    summary = []

                    for csv_name in csv_files:
                        with zip_ref.open(csv_name) as f:
                            try:
                                df = pd.read_csv(f)
                                df["__source_file__"] = os.path.basename(csv_name)
                                combined_df = pd.concat([combined_df, df], ignore_index=True)
                                summary.append((os.path.basename(csv_name), len(df)))
                            except Exception as e:
                                return f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª {csv_name}: {str(e)}"

                    GLOBAL_LOADED_DATA = combined_df
                    GLOBAL_SOURCE_SUMMARY = summary
                    return f"âœ… Loaded {len(summary)} CSV files from ZIP."

            except Exception as e:
                return f"âŒ ×©×’×™××” ×‘×¤×ª×™×—×ª ×§×•×‘×¥ ZIP: {str(e)}"

        else:
            return "âŒ ×¤×•×¨××˜ ×œ× × ×ª××š. ×™×© ×œ×¡×¤×§ ×§×•×‘×¥ CSV ××• ZIP."


# ğŸ”§ ×›×œ×™ 2 â€“ ×¡×™×›×•× ×›×©×œ×•× ×•×ª ×œ×¤×™ DUT_SN
class FailureCountPerUnitTool(BaseTool):
    name: ClassVar[str] = "failure_count_per_unit_tool"
    description: ClassVar[str] = (
        "×¡×•×¤×¨ ×›××•×ª ×›×©×œ×•× ×•×ª (Verdict_ATE == 0) ×œ×›×œ DUT_SN ×‘×›×œ ×”×§×‘×¦×™× ×©×˜×¢×•× ×™× ( ×ª×•××š ×’× ×‘-ZIP )."
    )

    def _run(self, query: str) -> str:
        df = get_loaded_data()
        if df is None or len(df) == 0:
            return "ğŸ‘­ ×œ× × ×˜×¢×Ÿ ×¢×“×™×™×Ÿ ×§×•×‘×¥ × ×ª×•× ×™×."

        if "Verdict_ATE" not in df.columns or "DUT_SN" not in df.columns:
            return "âš ï¸ ×—×¡×¨×•×ª ×¢××•×“×•×ª × ×“×¨×©×•×ª ('Verdict_ATE', 'DUT_SN')."

        failed_counts = df[df["Verdict_ATE"] == 0].groupby("DUT_SN").size().reset_index(name="Failures")
        if failed_counts.empty:
            return "âœ… ×œ× × ××¦××• ×›×©×œ×•× ×•×ª."

        return f"ğŸ“Š ×¡×™×›×•× ×›×©×œ×•× ×•×ª ×œ×¤×™ DUT_SN:\n\n{failed_counts.to_string(index=False)}"

    async def _arun(self, query: str) -> str:
        raise NotImplementedError("Async ×œ× × ×ª××š.")


# ğŸ”§ ×›×œ×™ 3 â€“ ×§×•×‘×¥ ×¢×œ ×©×“×•×ª ×©× ×›×©×œ×•
class FailureQueryTool(BaseTool):
    name: ClassVar[str] = "failure_query_tool"
    description: ClassVar[str] = "××—×–×™×¨ ×¢×¨×›×™× ××ª×•×š ×”×©×•×¨×•×ª ×©× ×›×©×œ×• ×œ×¤×™ ×©××•×ª ×¢××•×“×•×ª ×©×”×•×–×›×¨×• ×‘×©××œ×”."

    def _run(self, query: str) -> str:
        df = get_loaded_data()
        if df is None:
            return "ğŸ“¬ ×œ× × ×˜×¢×Ÿ ×¢×“×™×™×Ÿ ×§×•×‘×¥ × ×ª×•× ×™×."

        if "Verdict_ATE" not in df.columns:
            return "âŒ ×”×¢××•×“×” 'Verdict_ATE' ×œ× ×§×™×™××ª."

        failed_df = df[df["Verdict_ATE"] == 0]
        if failed_df.empty:
            return "âœ… ××™×Ÿ ×©×•×¨×•×ª ×©× ×›×©×œ×•."

        requested_cols = [col for col in df.columns if col.lower() in query.lower()]
        if not requested_cols:
            return "âš ï¸ ×œ× × ××¦××• ×¢××•×“×•×ª ×ª×•×××•×ª ×‘×©××œ×” ×©×œ×š."

        preview = failed_df[requested_cols].head(10).to_string(index=False)
        return f"ğŸ“‹ ×©×•×¨×•×ª ×©× ×›×©×œ×• ( ×¨××©×•× ×•×ª ):\n\n{preview}"


# ğŸ”§ ×›×œ×™ 4 â€“ ×¡×™×›×•× ×›×©×œ×™×
class FailureSummaryTool(BaseTool):
    name: ClassVar[str] = "failure_summary_tool"
    description: ClassVar[str] = "××¡×›× ××ª ×›×œ ×”×©×•×¨×•×ª ×©× ×›×©×œ×• ×›×•×œ×œ ×ª×“×¨, ×‘×“×™×§×”, ×’×‘×•×œ×•×ª, ×¢×¨×š, ×©×’×™××”, ×¢×¨×•×¥, ×¦'×™×¤ ×•â€PA."

    def _run(self, query: str) -> str:
        df = get_loaded_data()
        if df is None:
            return "ğŸ“¬ ×œ× × ×˜×¢×Ÿ ×¢×“×™×™×Ÿ ×§×•×‘×¥ × ×ª×•× ×™×."

        if "Verdict_ATE" not in df.columns:
            return "âŒ ×”×¢××•×“×” 'Verdict_ATE' ×œ× ×§×™×™××ª."

        failed_df = df[df["Verdict_ATE"] == 0]
        if failed_df.empty:
            return "âœ… ××™×Ÿ ×©×•×¨×•×ª ×©× ×›×©×œ×•."

        summaries = []
        for _, row in failed_df.iterrows():
            summary = (
                f"×ª×“×¨: {row.get('LOM_Freq_Config_MHz', 'N/A')} MHz, "
                f"×§×‘×•×¦×”: {row.get('Test_Group', 'N/A')}, ×‘×“×™×§×”: {row.get('Test_Name', 'N/A')}, "
                f"Chip: {row.get('Chip_Type', 'N/A')}, Chip_Num: {row.get('Chip_Num', 'N/A')}, "
                f"Channel: {row.get('Channel', 'N/A')}, PA: {row.get('PA', 'N/A')}\n"
                f"×ª×•×¦××”: {row.get('Result', 'N/A')} (×’×‘×•×œ×•×ª: {row.get('Min_Limit_ATE', 'N/A')} â€“ {row.get('Max_Limit_ATE', 'N/A')}), "
                f"×©×’×™××”: {row.get('Error_Msg', '××™×Ÿ')}\n"
            )
            summaries.append(summary)

        return f"× ××¦××• {len(failed_df)} ×©×•×¨×•×ª ×©× ×›×©×œ×•:\n\n" + "\n".join(summaries)


# ğŸ”§ ×›×œ×™ 5 â€“ ×’×¨×£ ×¤××¨×˜×• ×œ×¤×™ Sys_Type + ×ª×“×¨ + Test_Name
class FailureParetoTool(BaseTool):
    name: ClassVar[str] = "failure_pareto_tool"
    description: ClassVar[str] = "××¦×™×’ ×’×¨×£ ×¤××¨×˜×• ×©×œ ×›××•×ª ×›×©×œ×™× ×œ×¤×™ ×©×™×œ×•×‘ Sys_Type, LOM_Freq_Config_MHz ×•-Test_Name."

    def _run(self, query: str) -> str:
        df = get_loaded_data()
        if df is None:
            return "ğŸ“¬ ×œ× × ×˜×¢×Ÿ ×§×•×‘×¥ × ×ª×•× ×™×."

        if "Verdict_ATE" not in df.columns:
            return "âŒ ×”×¢××•×“×” 'Verdict_ATE' ×œ× ×§×™×™××ª."

        filtered_df = df[df["Verdict_ATE"] == 0]
        if filtered_df.empty:
            return "âœ… ××™×Ÿ ×›×©×œ×™× â€“ ××™×Ÿ ××” ×œ×”×¦×™×’ ×‘×’×¨×£."

        for col in ["Sys_Type", "LOM_Freq_Config_MHz", "Test_Name"]:
            if col not in filtered_df.columns:
                return f"âš ï¸ ×”×¢××•×“×” '{col}' ×œ× ×§×™×™××ª ×‘×§×•×‘×¥."

        filtered_df["Group"] = (
            filtered_df["Sys_Type"].astype(str) + " | " +
            filtered_df["LOM_Freq_Config_MHz"].astype(str) + " MHz | " +
            filtered_df["Test_Name"].astype(str)
        )

        counts = filtered_df.groupby("Group").size().sort_values(ascending=False)
        cumulative = counts.cumsum() / counts.sum() * 100

        fig, ax1 = plt.subplots(figsize=(12, 6))
        counts.plot(kind='bar', color='skyblue', ax=ax1)
        ax1.set_ylabel("×›××•×ª ×›×©×œ×™×")
        ax1.set_xlabel("Sys_Type | ×ª×“×¨ | Test_Name")
        ax1.set_title("ğŸ“Š ×’×¨×£ ×¤××¨×˜×• â€“ ×›××•×ª ×›×©×œ×™× ×œ×¤×™ ×©×™×œ×•×‘ ×¤×¨××˜×¨×™×")
        ax1.tick_params(axis='x', rotation=90)

        ax2 = ax1.twinx()
        cumulative.plot(color='red', marker='o', ax=ax2)
        ax2.set_ylabel("××—×•×– ××¦×˜×‘×¨")
        ax2.grid(False)

        plt.tight_layout()
        plt.show()

        return "ğŸ“ˆ ×’×¨×£ ×¤××¨×˜×• ×”×•×¦×’ ×‘×”×¦×œ×—×”."


# ğŸ”§ ×›×œ×™ 6 â€“ ××¢× ×” ×›×œ×œ×™×ª
class GeneralResponseTool(BaseTool):
    name: ClassVar[str] = "general_response_tool"
    description: ClassVar[str] = "×›×œ×™ ×œ×©××œ×•×ª ×›×œ×œ×™×•×ª ×›××• '××™ ××ª×”' ××• '×©×œ×•×'."

    def _run(self, query: str) -> str:
        return query


# âœ… ×¨×©×™××ª ×”×›×œ×™× ×œ×¡×•×›×Ÿ
TOOLS = [
    DataLoaderTool(),
    FailureCountPerUnitTool(),
    FailureQueryTool(),
    FailureSummaryTool(),
    FailureParetoTool(),
    GeneralResponseTool()
]
